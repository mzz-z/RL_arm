# default.yaml - Base configuration for all experiments
# This file contains all parameters; phase configs override specific values.

experiment:
  run_name: null              # Auto-generate if null
  seed: 42
  device: "cuda"              # "cpu" or "cuda"

  # Training duration
  total_env_steps: 10_000_000

  # Logging intervals
  log_interval_updates: 10
  eval_interval_updates: 50
  checkpoint_interval_updates: 100

  # Evaluation
  num_eval_episodes: 20
  eval_seeds: [100, 101, 102, 103, 104, 105, 106, 107, 108, 109,
               110, 111, 112, 113, 114, 115, 116, 117, 118, 119]

  # Best model tracking
  save_best_metric: "eval/success_rate"

  # Video recording (optional)
  record_video: false
  video_interval_updates: 200

env:
  task_mode: "reach"          # "reach" or "grasp"
  max_episode_steps: 200
  frame_skip: 4               # Sim steps per env step
  timestep: 0.002             # MuJoCo timestep (seconds)

  # Arm configuration (4-DOF with base rotation)
  arm:
    link1_length: 0.22        # meters
    link2_length: 0.18        # meters
    link3_length: 0.10        # meters (wrist segment)
    base_height: 0.42         # Height of shoulder above ground

  # Table
  table_height: 0.4

  # Ball
  ball:
    radius: 0.03
    mass: 0.05

  # Spawn parameters (ball position)
  spawn:
    radius_min: 0.15          # Min radial distance from base
    radius_max: 0.40          # Max radial distance (< link1 + link2)
    # Elevation angle: 0 is horizontal, positive is upward
    angle_min: 0.0            # At table level
    angle_max: 0.6            # Slightly upward (within reach)
    # Azimuth angle: rotation around z-axis for 3D spawning
    azimuth_min: -0.785           # ±π/4 default azimuth spread
    azimuth_max: 0.785

  # Initial arm state (within joint limits)
  init_joints:
    base_range: [-0.5, 0.5]
    shoulder_range: [0.1, 0.5]
    elbow_range: [-0.5, 0.0]
    wrist_range: [-0.3, 0.3]
    vel_noise_std: 0.01

  # Reach task parameters (Phase 1)
  reach:
    reach_radius: 0.05        # Success distance threshold (meters)
    dwell_steps: 5            # Steps within radius to succeed
    ee_vel_threshold: 0.1     # Max ee velocity for success (m/s)

  # Magnet grasp parameters (Phase 2)
  magnet:
    attach_radius: 0.04       # Distance to trigger attachment
    attach_vel_threshold: 0.15  # Max ee velocity to attach

  # Place parameters (Phase 2)
  place:
    place_radius: 0.05        # Distance to destination for success
    hold_steps: 10            # Steps at destination to succeed

  # Termination conditions
  termination:
    ball_fell_threshold: -0.05  # Ball z below table - this value
    unreachable_margin: 0.1     # Dist > max_reach + margin

control:
  mode: "position_target"
  action_scale: 0.15           # Radians per env step (CRITICAL)
  clip_action: true           # Clip actions to [-1, 1]

  # Optional rate limiting
  rate_limit:
    enabled: false
    max_delta: 0.15           # Max target change per step (rad)

  # Optional low-pass smoothing
  lowpass:
    enabled: false
    alpha: 0.3                # Smoothing factor

  # Joint limits (radians) - tuned to keep arm in useful workspace
  joint_limits:
    base: [-3.14159, 3.14159]
    shoulder: [0.0, 1.5]
    elbow: [-1.8, 0.3]
    wrist: [-1.5, 1.5]

reward:
  # Normalization
  normalize_distance: true    # Divide distance by max_reach

  # Smoothness penalties (low enough to allow bold multi-joint movement)
  w_action_mag: 0.005          # Penalty on ||action||^2
  w_action_change: 0.003      # Penalty on ||action - prev_action||^2
  w_joint_vel: 0.001           # Small penalty on joint velocities for smoothness

  # Phase 1: Reach
  reach:
    w_dist: 1.0               # Weight on (normalized) distance
    w_proximity: 0.5          # Exponential proximity bonus (stronger gradient near target)
    proximity_alpha: 5.0      # Steepness: higher = tighter focus on target
    success_bonus: 10.0       # Bonus for completing reach task

  # Phase 2: Grasp & Place
  grasp:
    w_dist: 1.0               # Pre-attach distance weight
    attach_bonus: 2.0         # One-time bonus for attachment
    w_place_dist: 1.0         # Post-attach distance to destination weight
    w_place_proximity: 0.5    # Exponential proximity bonus for destination
    place_proximity_alpha: 5.0  # Steepness of place proximity curve
    place_bonus: 5.0          # One-time bonus for reaching destination
    w_hold_per_step: 0.1      # Bonus per step at destination
    success_bonus: 15.0       # Bonus for completing pick-and-place

ppo:
  # Learning rate with scheduling
  lr: 3.0e-4
  lr_schedule: "linear"       # "linear", "cosine", or "constant"
  lr_min: 0.0                 # Minimum LR for cosine schedule

  # Discount and advantage
  gamma: 0.99
  gae_lambda: 0.95

  # PPO clipping
  clip_range: 0.2

  # Loss coefficients
  entropy_coef: 0.01
  value_coef: 0.5

  # Optimization
  max_grad_norm: 0.5
  target_kl: 0.02

  # Rollout collection
  rollout_steps: 2048         # Steps per env per update
  num_envs: 8                 # Parallel environments (CRITICAL)

  # Update epochs
  minibatch_size: 64
  epochs_per_update: 10

model:
  # Network architecture
  hidden_sizes: [256, 256]
  activation: "relu"          # "relu", "tanh", "elu"

  # Action distribution
  log_std_init: -0.5          # Initial log-std (std ≈ 0.6, tighter for 4-DOF)
  log_std_min: -20            # Clamp for numerical stability
  log_std_max: 0.5

  # Observation normalization
  obs_norm:
    enabled: true
    epsilon: 1.0e-8
    clip: 10.0                # Clip normalized obs to [-clip, clip]

training_assist:
  bc_warmup_steps: 0          # Behavioral cloning warmup steps (0 = disabled)

curriculum:
  enabled: false              # Set true to enable curriculum
  metric: "success_rate"      # Metric to track for advancement
  patience: 3                 # Evals above threshold before advancing
  stages: []
